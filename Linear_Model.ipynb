{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacky Boilerplates\n",
    "- Install `feast` with pip.\n",
    "- Activate user service account with credentials JSON.\n",
    "- Hacks to retrieve essential information for deployments and serving.\n",
    "\n",
    "**NOTE**: This code block might hangs for a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feast.sdk.resources.entity import Entity\n",
    "from feast.sdk.resources.storage import Storage\n",
    "from feast.sdk.resources.feature import Feature, Datastore, ValueType\n",
    "from feast.sdk.resources.feature_set import FeatureSet, FileType\n",
    "import feast.specs.FeatureSpec_pb2 as feature_pb\n",
    "\n",
    "from feast.sdk.importer import Importer\n",
    "\n",
    "from feast.sdk.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the local Feast deployment\n",
    "# FEAST_CORE_URL = '10.148.0.46:30576'\n",
    "FEAST_CORE_URL = 'localhost:6565'\n",
    "FEAST_SERVING_URL = 'localhost:6566'\n",
    "STAGING_LOCATION = 'gs://kubecon-19-gojek/staging'\n",
    "fs = Client(core_url=FEAST_CORE_URL,serving_url=FEAST_SERVING_URL, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-90aa9fd68ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcred_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GOOGLE_APPLICATION_CREDENTIALS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcred_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mcred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Install dependencies\n",
    "_ = subprocess.call(['pip', 'install', 'feast'], shell=True)\n",
    "# Retrieve user service account.\n",
    "_ = subprocess.call(['gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS'],\n",
    "                    shell=True)\n",
    "\n",
    "# Create KUBECONFIG. Use credential file to retrieve project/deployment names.\n",
    "cred_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "cred = {}\n",
    "with open(cred_path, 'r') as c:\n",
    "    cred = json.load(c)\n",
    "\n",
    "PROJECT = cred['project_id']\n",
    "APP_NAME = re.search('([a-z\\-]+)-user'.format(PROJECT),\n",
    "                     cred['client_email']).group(1)\n",
    "\n",
    "p = subprocess.Popen(['gcloud', 'container', 'clusters', 'list',\n",
    "                      '--filter', 'name=%s' % APP_NAME, '--format', 'json'],\n",
    "                    stdout=subprocess.PIPE)\n",
    "out, _ = p.communicate()\n",
    "config = json.loads(out)[0]\n",
    "ZONE = config['zone']\n",
    "\n",
    "print('PROJECT =', PROJECT)\n",
    "print('APP_NAME =', APP_NAME)\n",
    "print('ZONE =', ZONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load precomputed feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>datetime</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0.166550</td>\n",
       "      <td>0.077912</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 00:01:00</td>\n",
       "      <td>0.350554</td>\n",
       "      <td>0.378997</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 00:02:00</td>\n",
       "      <td>0.922618</td>\n",
       "      <td>0.317972</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 00:03:00</td>\n",
       "      <td>0.065824</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 00:04:00</td>\n",
       "      <td>0.847057</td>\n",
       "      <td>0.213472</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity            datetime  feature1  feature2  feature3  feature4\n",
       "0       0 2018-01-01 00:00:00  0.166550  0.077912         8         1\n",
       "1       0 2018-01-01 00:01:00  0.350554  0.378997         4         7\n",
       "2       0 2018-01-01 00:02:00  0.922618  0.317972         8         6\n",
       "3       0 2018-01-01 00:03:00  0.065824  0.055651         9         1\n",
       "4       0 2018-01-01 00:04:00  0.847057  0.213472         2        10"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', names=['entity','datetime','feature1','feature2','feature3','feature4'], index_col=False)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register entity and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully applied entity with name: simple_entity\n",
      "---\n",
      "name: simple_entity\n",
      "description: nyc taxi dataset\n",
      "\n",
      "Successfully applied feature with id: simple_entity.feature1\n",
      "---\n",
      "id: simple_entity.feature1\n",
      "name: feature1\n",
      "owner: user@website.com\n",
      "description: nyc taxi dataset\n",
      "valueType: DOUBLE\n",
      "entity: simple_entity\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: simple_entity.feature2\n",
      "---\n",
      "id: simple_entity.feature2\n",
      "name: feature2\n",
      "owner: user@website.com\n",
      "description: nyc taxi dataset\n",
      "valueType: DOUBLE\n",
      "entity: simple_entity\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: simple_entity.feature3\n",
      "---\n",
      "id: simple_entity.feature3\n",
      "name: feature3\n",
      "owner: user@website.com\n",
      "description: nyc taxi dataset\n",
      "valueType: INT64\n",
      "entity: simple_entity\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: simple_entity.feature4\n",
      "---\n",
      "id: simple_entity.feature4\n",
      "name: feature4\n",
      "owner: user@website.com\n",
      "description: nyc taxi dataset\n",
      "valueType: INT64\n",
      "entity: simple_entity\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Staging file to remote path gs://kubecon-19-gojek/staging/tmp_simple_entity_1557651046538.csv\n",
      "Submitting job with spec:\n",
      " type: file.csv\n",
      "sourceOptions:\n",
      "  path: gs://kubecon-19-gojek/staging/tmp_simple_entity_1557651046538.csv\n",
      "entities:\n",
      "- simple_entity\n",
      "schema:\n",
      "  entityIdColumn: entity\n",
      "  fields:\n",
      "  - name: entity\n",
      "  - name: datetime\n",
      "  - featureId: simple_entity.feature1\n",
      "    name: feature1\n",
      "  - featureId: simple_entity.feature2\n",
      "    name: feature2\n",
      "  - featureId: simple_entity.feature3\n",
      "    name: feature3\n",
      "  - featureId: simple_entity.feature4\n",
      "    name: feature4\n",
      "  timestampColumn: datetime\n",
      "\n",
      "Submitted job with id: feastimport1557651048059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'feastimport1557651048059'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from feast.sdk.resources.entity import Entity\n",
    "# from feast.sdk.resources.feature import Feature\n",
    "\n",
    "\n",
    "# # Register a simple entity\n",
    "# demo_entity = Entity(name='demo_entity', description='My simple demo entity')\n",
    "# fs.apply(demo_entity)\n",
    "\n",
    "# # Register five numeric features on this entity\n",
    "# from feast.sdk.resources.feature import Feature\n",
    "\n",
    "# my_simple\n",
    "\n",
    "# Now that we have finished creating our features, we ingest them into feast\n",
    "\n",
    "#Remove this later...\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/jovyan/key.json'\n",
    "\n",
    "# Create importer\n",
    "importer = Importer.from_df(df, \n",
    "                           entity='simple_entity', \n",
    "                           owner='user@website.com',  \n",
    "                           staging_location=STAGING_LOCATION,\n",
    "                           id_column='entity', \n",
    "                           timestamp_column='datetime',\n",
    "                           serving_store=Datastore(id='SERVING'),\n",
    "                           warehouse_store=Datastore(id='WAREHOUSE'))\n",
    "\n",
    "# Update feature and entity metadata. Ideally you want to update these manually\n",
    "# so that they contain adequate information for the next user\n",
    "importer.entity.description = 'entity level description' \n",
    "for feature_id in importer.features:\n",
    "    importer.features[feature_id].description = 'feature level description'\n",
    "    \n",
    "# Ingest the feature data into the store\n",
    "fs.run(importer, apply_features=True, apply_entity=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Feature Set for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = FeatureSet(\n",
    "                entity=\"simple_entity\",\n",
    "                features=[\n",
    "                 \"simple_entity.feature1\",\n",
    "                 \"simple_entity.feature2\",\n",
    "                 \"simple_entity.feature3\",\n",
    "                 \"simple_entity.feature4\",\n",
    "                ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating training dataset for features: ['simple_entity.feature1', 'simple_entity.feature2', 'simple_entity.feature3', 'simple_entity.feature4']\n",
      "created dataset simple_entity_1557654531760_20180101_20180131: aliz-development.fs_simple_entity.1557654531760_20180101_20180131\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Retrieve feature data for training from Feast\n",
    "dataset = fs.create_dataset(feature_set, \"2018-01-01\", \"2018-01-31\")\n",
    "feast_df = fs.download_dataset_to_df(dataset, STAGING_LOCATION)\n",
    "feast_df.head()\n",
    "\n",
    "# Train model\n",
    "train_data = np.random.randint(1, high=100, size=(200, 100))\n",
    "A = np.insert(train_data, 100, 1, axis=1)\n",
    "Y = np.random.randint(1, high=100, size=200)\n",
    "\n",
    "x = np.linalg.lstsq(A, Y, rcond=0)[0]\n",
    "m, b = x[:100], x[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  simple_entity  simple_entity.feature1  simple_entity.feature2  \\\n",
      "0             3                   0.355                0.181848   \n",
      "\n",
      "   simple_entity.feature3  simple_entity.feature4  \n",
      "0                       1                       9  \n",
      "[22.747 33.055 32.469 30.373 33.915 40.367 15.002 34.548 37.274 31.25\n",
      " 31.79  31.466 31.425 58.343 50.559 34.345 40.636 34.359 35.336 31.335\n",
      " 33.974 37.882 34.533 36.43  34.398 34.26  39.955 33.492 28.59  33.865\n",
      " 36.471 42.761 48.122 31.441 34.952 35.107 36.218 24.593 42.834 31.399\n",
      " 30.178 44.628 39.829 27.065 26.961 30.02  30.254 14.452 36.935 46.906\n",
      " 29.151 42.793 43.954 38.123 31.587 33.648 33.781 36.914 34.261 31.373\n",
      " 34.364 43.014 31.788 33.232 25.62  44.813 35.674 27.418 49.595 26.842\n",
      " 35.961 32.65  35.478 35.816 34.258 21.608 34.125 34.436 35.6   35.741\n",
      " 39.95  39.782 30.949 33.215 32.904 34.686 32.695 33.929 34.098 40.002\n",
      " 37.816 35.491 35.927 33.572 34.955 26.932 17.624 32.196 35.43  36.807]\n"
     ]
    }
   ],
   "source": [
    "# retrieve features from Feast serving\n",
    "entity_id = '3' # this would typically be the user id\n",
    "features = fs.get_serving_data(feature_set,entity_keys=[entity_id])\n",
    "print(features)\n",
    "\n",
    "# we should also probably change x to \"id\"\n",
    "def local_predict(x):\n",
    "    # normally the Feast client would be inserted here.\n",
    "    return m * x + b\n",
    "\n",
    "feature = np.random.randint(1, high=100, size=100)\n",
    "p = local_predict(feature)\n",
    "np.set_printoptions(precision=3)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "MODEL_FILE = 'simple_model.dat'\n",
    "\n",
    "model = {\n",
    "    'm': m.tolist(),\n",
    "    'b': b,\n",
    "}\n",
    "\n",
    "model_path = os.path.join(os.getenv('HOME', '/home'), MODEL_FILE)\n",
    "print('writing to', model_path)\n",
    "\n",
    "with open(model_path, 'w+') as f:\n",
    "    json.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy with Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairing\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(PROJECT)\n",
    "BASE_IMAGE = 'gcr.io/kubeflow-images-public/fairing-base:v20190510'\n",
    "SERVING_LABEL = 'kubeflow-fairing-demo'\n",
    "\n",
    "print('docker registry:', DOCKER_REGISTRY)\n",
    "print('base image:', BASE_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deploy_with_fairing\n",
    "import uuid\n",
    "\n",
    "# To disambiguate between different deployments.\n",
    "serving_label = SERVING_LABEL + '-' + uuid.uuid4().hex[:4]\n",
    "print('Deploying service with selector', serving_label)\n",
    "\n",
    "# Register for docker credential. Needed for docker image pushes.\n",
    "_ = subprocess.call(['gcloud auth configure-docker --quiet'], shell=True)\n",
    "\n",
    "importlib.reload(deploy_with_fairing)\n",
    "deploy_with_fairing.deploy(DOCKER_REGISTRY, BASE_IMAGE, serving_label=serving_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from kubernetes import client, config\n",
    "\n",
    "# Need to set up KUBECONFIG. Kubernetes API client depends on it.\n",
    "subprocess.call(['gcloud', 'container', 'clusters', 'get-credentials', APP_NAME,\n",
    "                 '--zone', ZONE, '--project', PROJECT])\n",
    "config.load_kube_config()\n",
    "c = client.Configuration()\n",
    "client.Configuration.set_default(c)\n",
    "\n",
    "v1 = client.CoreV1Api()\n",
    "body = client.V1Service()\n",
    "label_selector = 'serving=%s' % serving_label\n",
    "resp = v1.list_service_for_all_namespaces(label_selector=label_selector)\n",
    "\n",
    "service_name = resp.items[0].metadata.name\n",
    "namespace = resp.items[0].metadata.namespace\n",
    "\n",
    "print('fairing service: {0}/{1}'.format(namespace, service_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving with Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def predict(url, data, feature_names=None):\n",
    "    pdata={\n",
    "        \"data\": {\n",
    "            \"names\":feature_names,\n",
    "            \"tensor\": {\n",
    "                \"shape\": np.asarray(data.shape).tolist(),\n",
    "                \"values\": data.flatten().tolist(),\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    serialized_data = json.dumps(pdata)\n",
    "    r = requests.post(url, data={'json':serialized_data})\n",
    "    return r\n",
    "\n",
    "def extract_prediction_array(content):\n",
    "    c = json.loads(content)\n",
    "    return np.array(c.get('data', {}).get('tensor', {}).get('values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "url = \"http://{service_name}.{namespace}.svc.cluster.local:5000/predict\".format(\n",
    "    service_name=service_name,\n",
    "    namespace=namespace)\n",
    "\n",
    "data = np.random.randint(1, high=100, size=100)\n",
    "r = predict(url, data)\n",
    "\n",
    "prediction = extract_prediction_array(r.content)\n",
    "print('prediction:')\n",
    "pprint.pprint(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
