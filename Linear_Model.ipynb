{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacky Boilerplates\n",
    "- Install `feast` with pip.\n",
    "- Activate user service account with credentials JSON.\n",
    "- Hacks to retrieve essential information for deployments and serving.\n",
    "\n",
    "**NOTE**: This code block might hangs for a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feast in /opt/conda/lib/python3.6/site-packages (0.1.0.post0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from feast) (0.24.2)\n",
      "Requirement already satisfied: grpcio>=1.16.1 in /opt/conda/lib/python3.6/site-packages (from feast) (1.19.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from feast) (1.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from feast) (1.11.2)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.5.5 in /opt/conda/lib/python3.6/site-packages (from feast) (1.5.9)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from feast) (3.7.1)\n",
      "Requirement already satisfied: google-auth>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from feast) (1.6.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.6/site-packages (from feast) (5.1)\n",
      "Requirement already satisfied: google-api-core>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from feast) (1.9.0)\n",
      "Requirement already satisfied: fastavro>=0.21.19 in /opt/conda/lib/python3.6/site-packages (from feast) (0.21.23)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->feast) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->feast) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from pandas->feast) (1.16.2)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.6/site-packages (from grpcio>=1.16.1->feast) (1.12.0)\n",
      "Requirement already satisfied: google-resumable-media>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->feast) (0.3.2)\n",
      "Requirement already satisfied: google-cloud-core<0.30dev,>=0.29.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->feast) (0.29.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.0.0->feast) (40.9.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.0->feast) (3.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.0->feast) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.0->feast) (0.2.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core>=1.7.0->feast) (2.21.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth>=1.6.0->feast) (0.4.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core>=1.7.0->feast) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core>=1.7.0->feast) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core>=1.7.0->feast) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core>=1.7.0->feast) (2.8)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Activated service account credentials for: [kubeflow-asia-user@aliz-development.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "# Install feast\n",
    "!pip install feast\n",
    "\n",
    "# Retrieve user service account.\n",
    "!gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT = aliz-development\n",
      "APP_NAME = kubeflow-asia\n",
      "ZONE = asia-southeast1-a\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "cred_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "cred = {}\n",
    "with open(cred_path, 'r') as c:\n",
    "    cred = json.load(c)\n",
    "\n",
    "PROJECT = cred['project_id']\n",
    "APP_NAME = re.search('([a-z\\-]+)-user'.format(PROJECT),\n",
    "                     cred['client_email']).group(1)\n",
    "p = subprocess.Popen(['gcloud', 'container', 'clusters', 'list',\n",
    "                      '--filter', 'name=%s' % APP_NAME, '--format', 'json'],\n",
    "                    stdout=subprocess.PIPE)\n",
    "out, _ = p.communicate()\n",
    "config = json.loads(out)[0]\n",
    "ZONE = config['zone']\n",
    "\n",
    "print('PROJECT =', PROJECT)\n",
    "print('APP_NAME =', APP_NAME)\n",
    "print('ZONE =', ZONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feast.sdk.resources.entity import Entity\n",
    "from feast.sdk.resources.storage import Storage\n",
    "from feast.sdk.resources.feature import Feature, Datastore, ValueType\n",
    "from feast.sdk.resources.feature_set import FeatureSet, FileType\n",
    "import feast.specs.FeatureSpec_pb2 as feature_pb\n",
    "\n",
    "from feast.sdk.importer import Importer\n",
    "\n",
    "from feast.sdk.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the local Feast deployment\n",
    "# FEAST_CORE_URL = '10.148.0.46:30576'\n",
    "# TODO(gabrielwen): Use internal DNS?\n",
    "FEAST_CORE_URL = '10.148.0.99:6565'\n",
    "FEAST_SERVING_URL = '10.148.0.100:6566'\n",
    "STAGING_LOCATION = 'gs://kubecon-19-gojek/staging'\n",
    "fs = Client(core_url=FEAST_CORE_URL,serving_url=FEAST_SERVING_URL, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load precomputed feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_area_income</th>\n",
       "      <th>avg_area_house_age</th>\n",
       "      <th>avg_area_number_of_rooms</th>\n",
       "      <th>avg_area_number_of_bedrooms</th>\n",
       "      <th>area_population</th>\n",
       "      <th>price</th>\n",
       "      <th>area_code</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.458574</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.800503</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>NE 37010-5101</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.642455</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.072174</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>CA 48958</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.067179</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.159400</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>WI 06482-3489</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.240046</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.242831</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>FPO AP 44820</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.197226</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.109472</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>FPO AE 09386</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_area_income  avg_area_house_age  avg_area_number_of_rooms  \\\n",
       "0     79545.458574            5.682861                  7.009188   \n",
       "1     79248.642455            6.002900                  6.730821   \n",
       "2     61287.067179            5.865890                  8.512727   \n",
       "3     63345.240046            7.188236                  5.586729   \n",
       "4     59982.197226            5.040555                  7.839388   \n",
       "\n",
       "   avg_area_number_of_bedrooms  area_population         price      area_code  \\\n",
       "0                         4.09     23086.800503  1.059034e+06  NE 37010-5101   \n",
       "1                         3.09     40173.072174  1.505891e+06       CA 48958   \n",
       "2                         5.13     36882.159400  1.058988e+06  WI 06482-3489   \n",
       "3                         3.26     34310.242831  1.260617e+06   FPO AP 44820   \n",
       "4                         4.23     26354.109472  6.309435e+05   FPO AE 09386   \n",
       "\n",
       "   timestamp  \n",
       "0 2018-01-01  \n",
       "1 2018-01-01  \n",
       "2 2018-01-01  \n",
       "3 2018-01-01  \n",
       "4 2018-01-01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('usa_housing.csv', index_col=False)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register entity and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully applied entity with name: usa_housing\n",
      "---\n",
      "name: usa_housing\n",
      "description: entity level description\n",
      "\n",
      "Successfully applied feature with id: usa_housing.avg_area_income\n",
      "---\n",
      "id: usa_housing.avg_area_income\n",
      "name: avg_area_income\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.avg_area_house_age\n",
      "---\n",
      "id: usa_housing.avg_area_house_age\n",
      "name: avg_area_house_age\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.avg_area_number_of_rooms\n",
      "---\n",
      "id: usa_housing.avg_area_number_of_rooms\n",
      "name: avg_area_number_of_rooms\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.avg_area_number_of_bedrooms\n",
      "---\n",
      "id: usa_housing.avg_area_number_of_bedrooms\n",
      "name: avg_area_number_of_bedrooms\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.area_population\n",
      "---\n",
      "id: usa_housing.area_population\n",
      "name: area_population\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.price\n",
      "---\n",
      "id: usa_housing.price\n",
      "name: price\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Staging file to remote path gs://kubecon-19-gojek/staging/tmp_usa_housing_1558033509174.csv\n",
      "Submitting job with spec:\n",
      " type: file.csv\n",
      "sourceOptions:\n",
      "  path: gs://kubecon-19-gojek/staging/tmp_usa_housing_1558033509174.csv\n",
      "entities:\n",
      "- usa_housing\n",
      "schema:\n",
      "  entityIdColumn: area_code\n",
      "  fields:\n",
      "  - featureId: usa_housing.avg_area_income\n",
      "    name: avg_area_income\n",
      "  - featureId: usa_housing.avg_area_house_age\n",
      "    name: avg_area_house_age\n",
      "  - featureId: usa_housing.avg_area_number_of_rooms\n",
      "    name: avg_area_number_of_rooms\n",
      "  - featureId: usa_housing.avg_area_number_of_bedrooms\n",
      "    name: avg_area_number_of_bedrooms\n",
      "  - featureId: usa_housing.area_population\n",
      "    name: area_population\n",
      "  - featureId: usa_housing.price\n",
      "    name: price\n",
      "  - name: area_code\n",
      "  - name: timestamp\n",
      "  timestampColumn: timestamp\n",
      "\n",
      "Submitted job with id: feastimport1558033510821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'feastimport1558033510821'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from feast.sdk.resources.entity import Entity\n",
    "# from feast.sdk.resources.feature import Feature\n",
    "\n",
    "\n",
    "# # Register a simple entity\n",
    "# demo_entity = Entity(name='demo_entity', description='My simple demo entity')\n",
    "# fs.apply(demo_entity)\n",
    "\n",
    "# # Register five numeric features on this entity\n",
    "# from feast.sdk.resources.feature import Feature\n",
    "\n",
    "# my_simple\n",
    "\n",
    "# Now that we have finished creating our features, we ingest them into feast\n",
    "\n",
    "# Create importer\n",
    "importer = Importer.from_df(df, \n",
    "                           entity='usa_housing', \n",
    "                           owner='user@website.com',  \n",
    "                           staging_location=STAGING_LOCATION,\n",
    "                           id_column='area_code', \n",
    "                           timestamp_column='timestamp',\n",
    "                           serving_store=Datastore(id='SERVING'),\n",
    "                           warehouse_store=Datastore(id='WAREHOUSE'))\n",
    "\n",
    "# Update feature and entity metadata. Ideally you want to update these manually\n",
    "# so that they contain adequate information for the next user\n",
    "importer.entity.description = 'entity level description' \n",
    "for feature_id in importer.features:\n",
    "    importer.features[feature_id].description = 'feature level description'\n",
    "    \n",
    "# Ingest the feature data into the store\n",
    "fs.run(importer, apply_features=True, apply_entity=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Feature Set for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_ID = 'usa_housing'\n",
    "FEATURES_SET = [\n",
    "    'usa_housing.avg_area_income',\n",
    "    'usa_housing.avg_area_house_age',\n",
    "    'usa_housing.avg_area_number_of_rooms',\n",
    "    'usa_housing.avg_area_number_of_bedrooms',\n",
    "    'usa_housing.area_population',\n",
    "]\n",
    "\n",
    "feature_set = FeatureSet(entity=ENTITY_ID, \n",
    "                         features=FEATURES_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve a Training Set from Feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature data for training from Feast\n",
    "dataset = fs.create_dataset(feature_set, \"2018-01-01\", \"2018-01-31\")\n",
    "training_df = fs.download_dataset_to_df(dataset, STAGING_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Train model\n",
    "train_data = training_df[[x.split('.')[1] for x in FEATURES_SET]].to_numpy()\n",
    "A = np.insert(train_data, len(train_data[0]), 1, axis=1)\n",
    "Y = training_df['price'].to_numpy()\n",
    "\n",
    "x = np.linalg.lstsq(A, Y, rcond=0)[0]\n",
    "m, b = x[:len(A[0])-1], x[len(A[0])-1]\n",
    "\n",
    "print(m, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_fs = FeatureSet(entity=ENTITY_ID, features=FEATURES_SET)\n",
    "\n",
    "def local_predict(id):\n",
    "    # retrieve features from Feast serving\n",
    "    features = fs.get_serving_data(serving_fs, entity_keys=[id])\n",
    "    x = features.to_numpy()[0][1:]\n",
    "    return sum(m * x) + b\n",
    "\n",
    "p = local_predict('FPO AE 09386')\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "MODEL_FILE = 'simple_model.dat'\n",
    "\n",
    "model = {\n",
    "    'm': m.tolist(),\n",
    "    'b': b,\n",
    "    'FEAST_CORE_URL': FEAST_CORE_URL,\n",
    "    'FEAST_SERVING_URL': FEAST_SERVING_URL,\n",
    "    'ENTITY_ID': ENTITY_ID,\n",
    "    'FEATURES_SET': FEATURES_SET,\n",
    "}\n",
    "\n",
    "# TODO(gabrielwen): Use PWD instead.\n",
    "model_path = os.path.join(os.getenv('HOME', '/home'), MODEL_FILE)\n",
    "print('writing to', model_path)\n",
    "\n",
    "with open(model_path, 'w+') as f:\n",
    "    json.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy with Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m `docker` not in system PATH.\n",
      "`docker` and `docker-credential-gcloud` need to be in the same PATH in order to work correctly together.\n",
      "gcloud's Docker credential helper can be configured but it will not work until this is corrected.\n",
      "gcloud credential helpers already registered correctly.\n",
      "Activated service account credentials for: [kubeflow-asia-user@aliz-development.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "# Register for docker credential. Needed for docker image pushes.\n",
    "!gcloud auth configure-docker --quiet\n",
    "\n",
    "# Retrieve user service account.\n",
    "!gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker registry: gcr.io/aliz-development/fairing-job\n",
      "base image: gcr.io/kubeflow-images-public/fairing-base:v20190516\n"
     ]
    }
   ],
   "source": [
    "import fairing\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(PROJECT)\n",
    "BASE_IMAGE = 'gcr.io/kubeflow-images-public/fairing-base:v20190516'\n",
    "SERVING_LABEL = 'kubeflow-fairing-demo'\n",
    "\n",
    "print('docker registry:', DOCKER_REGISTRY)\n",
    "print('base image:', BASE_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building image...\n",
      "Loading Docker credentials for repository 'gcr.io/kubeflow-images-public/fairing-base:v20190516'\n",
      "Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying service with selector kubeflow-fairing-demo-a1db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully obtained Docker credentials.\n",
      "Image successfully built in 1.8694912969949655s.\n",
      "Pushing image gcr.io/aliz-development/fairing-job/fairing-job:10591BC2...\n",
      "Loading Docker credentials for repository 'gcr.io/aliz-development/fairing-job/fairing-job:10591BC2'\n",
      "Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "Successfully obtained Docker credentials.\n",
      "Uploading gcr.io/aliz-development/fairing-job/fairing-job:10591BC2\n",
      "Layer sha256:5d71636fb824265e30ff34bf20737c9cdc4f5af28b6bce86f08215c55b89bfab exists, skipping\n",
      "Layer sha256:46b64f8f5cd275ca04071c8cd36170990c26b5cce6bcb440579cb4a9094fc7b4 exists, skipping\n",
      "Layer sha256:620aea26e85367b08cdf1f6768491fb44df6a2a71f7d663f835b1692e849c3ee exists, skipping\n",
      "Layer sha256:a8c5303780550b746a4781e5e4cd893121d8019e971414a2a1273d54486b4eb9 exists, skipping\n",
      "Layer sha256:425317e6171bfb0c70b2fa348dfcc0ae2166734273450aa05aa04be43b9278d7 exists, skipping\n",
      "Layer sha256:d6341e30912f12f56e18564a3b582853f65376766f5f9d641a68a724ed6db88f exists, skipping\n",
      "Layer sha256:df57ae687ef5b466a3e956951a4a61f879084f89228b7d34cf20eee4b730f160 exists, skipping\n",
      "Layer sha256:1e33f14f5f4ae8acc90736eddcf5f1667c15829f343954164b6099d37e40c3e9 exists, skipping\n",
      "Layer sha256:3685478d4d9b72bd0c88c3e3a415d3d25d19042452b672d2befb2b6e6f1d1bbc exists, skipping\n",
      "Layer sha256:087a57faf9491b1b82a83e26bc8cc90c90c30e4a4d858b57ddd5b4c2c90095f6 exists, skipping\n",
      "Layer sha256:687ed2fb2a0d7da5503478759fd00c23970b65d02b317119b3fb9025038a2594 exists, skipping\n",
      "Layer sha256:54f7e8ac135a5f502a6ee9537ef3d64b1cd2fa570dc0a40b4d3b6f7ac81e7486 exists, skipping\n",
      "Layer sha256:a86c8ce7a2ae5a681a1a702074121ed8c6df9b2f044e61c6aacd87e4c80f7299 exists, skipping\n",
      "Layer sha256:2eeb5ce9b9240a928b0a799f9f2601027e2c6b7525394ae5c371f124058489d7 exists, skipping\n",
      "Layer sha256:0c1db95989906f161007d8ef2a6ef6e0ec64bc15bf2c993fd002edbdfc7aa7df exists, skipping\n",
      "Layer sha256:da4d8c6b3f1d6f339ae31ab5624be041df02aff9d3f7f085bee0be70d5510be9 exists, skipping\n",
      "Layer sha256:291a1cd417b9a46e6fb6e528bda6b0ec6e781bc1614786b68906a9d4e55f8e1f pushed.\n",
      "Layer sha256:74a5ae26d4757c5b88dc0c9e883e6287cba80b1cbda2c2047d9fab08416eebfa pushed.\n",
      "Finished upload of: gcr.io/aliz-development/fairing-job/fairing-job:10591BC2\n",
      "Pushed image gcr.io/aliz-development/fairing-job/fairing-job:10591BC2 in 8.656844797020312s.\n",
      "Endpoint fairing-deployer-rb8p8 launched.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for prediction endpoint to come up...\n"
     ]
    }
   ],
   "source": [
    "import deploy_with_fairing\n",
    "import uuid\n",
    "\n",
    "# To disambiguate between different deployments.\n",
    "serving_label = SERVING_LABEL + '-' + uuid.uuid4().hex[:4]\n",
    "print('Deploying service with selector', serving_label)\n",
    "\n",
    "# TODO(gabrielwen): Re-deploy has permission issue.\n",
    "importlib.reload(deploy_with_fairing)\n",
    "deploy_with_fairing.deploy(DOCKER_REGISTRY, BASE_IMAGE, serving_label=serving_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch fairing service endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for kubeflow-asia.\n"
     ]
    }
   ],
   "source": [
    "# Need to set up KUBECONFIG. Kubernetes API client depends on it.\n",
    "!gcloud container clusters get-credentials \"$APP_NAME\" --zone \"$ZONE\" --project \"$PROJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairing service: kubeflow/fairing-service-snxqf\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from kubernetes import client, config\n",
    "\n",
    "config.load_kube_config()\n",
    "c = client.Configuration()\n",
    "client.Configuration.set_default(c)\n",
    "\n",
    "v1 = client.CoreV1Api()\n",
    "body = client.V1Service()\n",
    "label_selector = 'serving=%s' % serving_label\n",
    "resp = v1.list_service_for_all_namespaces(label_selector=label_selector)\n",
    "\n",
    "service_name = resp.items[0].metadata.name\n",
    "namespace = resp.items[0].metadata.namespace\n",
    "\n",
    "print('fairing service: {0}/{1}'.format(namespace, service_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving with Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def predict(url, id):\n",
    "    pdata={\n",
    "        'strData': id,\n",
    "    }\n",
    "    serialized_data = json.dumps(pdata)\n",
    "    r = requests.post(url, data={'json':serialized_data})\n",
    "    return r\n",
    "\n",
    "def extract_prediction_array(content):\n",
    "    c = json.loads(content)\n",
    "    return np.array(c.get('data', {}).get('ndarray', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      "array([-1343000.21557071, -1802396.56798744, -1691398.90442468,\n",
      "       -2630314.71512979, -2236696.9639044 ])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "url = \"http://{service_name}.{namespace}.svc.cluster.local:5000/predict\".format(\n",
    "    service_name=service_name,\n",
    "    namespace=namespace)\n",
    "\n",
    "r = predict(url, 'FPO AE 09386')\n",
    "prediction = extract_prediction_array(r.content)\n",
    "print('prediction:')\n",
    "pprint.pprint(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
