{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacky Boilerplates\n",
    "- Install `feast` with pip.\n",
    "- Activate user service account with credentials JSON.\n",
    "- Hacks to retrieve essential information for deployments and serving.\n",
    "\n",
    "**NOTE**: This code block might hangs for a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feast in /opt/conda/lib/python3.6/site-packages (0.1.0.post0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from feast) (0.24.2)\n",
      "Requirement already satisfied: fastavro>=0.21.19 in /opt/conda/lib/python3.6/site-packages (from feast) (0.21.23)\n",
      "Requirement already satisfied: google-cloud-bigquery>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from feast) (1.11.2)\n",
      "Requirement already satisfied: google-api-core>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from feast) (1.9.0)\n",
      "Requirement already satisfied: grpcio>=1.16.1 in /opt/conda/lib/python3.6/site-packages (from feast) (1.19.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.6/site-packages (from feast) (5.1)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from feast) (1.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.5.5 in /opt/conda/lib/python3.6/site-packages (from feast) (1.5.9)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from feast) (3.7.1)\n",
      "Requirement already satisfied: google-auth>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from feast) (1.6.3)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->feast) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->feast) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from pandas->feast) (1.16.2)\n",
      "Requirement already satisfied: google-cloud-core<0.30dev,>=0.29.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigquery>=1.8.0->feast) (0.29.1)\n",
      "Requirement already satisfied: google-resumable-media>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-bigquery>=1.8.0->feast) (0.3.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core>=1.7.0->feast) (1.12.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core>=1.7.0->feast) (2.21.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core>=1.7.0->feast) (40.9.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.0->feast) (4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.0->feast) (3.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.0->feast) (0.2.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core>=1.7.0->feast) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core>=1.7.0->feast) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core>=1.7.0->feast) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core>=1.7.0->feast) (2019.3.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth>=1.6.0->feast) (0.4.5)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Activated service account credentials for: [kubeflow-asia-user@aliz-development.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "# Install feast\n",
    "!pip install feast\n",
    "\n",
    "# Retrieve user service account.\n",
    "!gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT = aliz-development\n",
      "APP_NAME = kubeflow-asia\n",
      "ZONE = asia-southeast1-a\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "cred_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "cred = {}\n",
    "with open(cred_path, 'r') as c:\n",
    "    cred = json.load(c)\n",
    "\n",
    "PROJECT = cred['project_id']\n",
    "APP_NAME = re.search('([a-z\\-]+)-user'.format(PROJECT),\n",
    "                     cred['client_email']).group(1)\n",
    "p = subprocess.Popen(['gcloud', 'container', 'clusters', 'list',\n",
    "                      '--filter', 'name=%s' % APP_NAME, '--format', 'json'],\n",
    "                    stdout=subprocess.PIPE)\n",
    "out, _ = p.communicate()\n",
    "config = json.loads(out)[0]\n",
    "ZONE = config['zone']\n",
    "\n",
    "print('PROJECT =', PROJECT)\n",
    "print('APP_NAME =', APP_NAME)\n",
    "print('ZONE =', ZONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feast.sdk.resources.entity import Entity\n",
    "from feast.sdk.resources.storage import Storage\n",
    "from feast.sdk.resources.feature import Feature, Datastore, ValueType\n",
    "from feast.sdk.resources.feature_set import FeatureSet, FileType\n",
    "import feast.specs.FeatureSpec_pb2 as feature_pb\n",
    "\n",
    "from feast.sdk.importer import Importer\n",
    "\n",
    "from feast.sdk.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the local Feast deployment\n",
    "# FEAST_CORE_URL = '10.148.0.46:30576'\n",
    "FEAST_CORE_URL = '10.148.0.99:6565'\n",
    "FEAST_SERVING_URL = '10.148.0.100:6566'\n",
    "STAGING_LOCATION = 'gs://kubecon-19-gojek/staging'\n",
    "fs = Client(core_url=FEAST_CORE_URL,serving_url=FEAST_SERVING_URL, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load precomputed feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_area_income</th>\n",
       "      <th>avg_area_house_age</th>\n",
       "      <th>avg_area_number_of_rooms</th>\n",
       "      <th>avg_area_number_of_bedrooms</th>\n",
       "      <th>area_population</th>\n",
       "      <th>price</th>\n",
       "      <th>area_code</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.458574</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.800503</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>NE 37010-5101</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.642455</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.072174</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>CA 48958</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.067179</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.159400</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>WI 06482-3489</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.240046</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.242831</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>FPO AP 44820</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.197226</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.109472</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>FPO AE 09386</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_area_income  avg_area_house_age  avg_area_number_of_rooms  \\\n",
       "0     79545.458574            5.682861                  7.009188   \n",
       "1     79248.642455            6.002900                  6.730821   \n",
       "2     61287.067179            5.865890                  8.512727   \n",
       "3     63345.240046            7.188236                  5.586729   \n",
       "4     59982.197226            5.040555                  7.839388   \n",
       "\n",
       "   avg_area_number_of_bedrooms  area_population         price      area_code  \\\n",
       "0                         4.09     23086.800503  1.059034e+06  NE 37010-5101   \n",
       "1                         3.09     40173.072174  1.505891e+06       CA 48958   \n",
       "2                         5.13     36882.159400  1.058988e+06  WI 06482-3489   \n",
       "3                         3.26     34310.242831  1.260617e+06   FPO AP 44820   \n",
       "4                         4.23     26354.109472  6.309435e+05   FPO AE 09386   \n",
       "\n",
       "   timestamp  \n",
       "0 2018-01-01  \n",
       "1 2018-01-01  \n",
       "2 2018-01-01  \n",
       "3 2018-01-01  \n",
       "4 2018-01-01  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('usa_housing.csv', index_col=False)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register entity and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully applied entity with name: usa_housing\n",
      "---\n",
      "name: usa_housing\n",
      "description: entity level description\n",
      "\n",
      "Successfully applied feature with id: usa_housing.avg_area_income\n",
      "---\n",
      "id: usa_housing.avg_area_income\n",
      "name: avg_area_income\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.avg_area_house_age\n",
      "---\n",
      "id: usa_housing.avg_area_house_age\n",
      "name: avg_area_house_age\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.avg_area_number_of_rooms\n",
      "---\n",
      "id: usa_housing.avg_area_number_of_rooms\n",
      "name: avg_area_number_of_rooms\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.avg_area_number_of_bedrooms\n",
      "---\n",
      "id: usa_housing.avg_area_number_of_bedrooms\n",
      "name: avg_area_number_of_bedrooms\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.area_population\n",
      "---\n",
      "id: usa_housing.area_population\n",
      "name: area_population\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Successfully applied feature with id: usa_housing.price\n",
      "---\n",
      "id: usa_housing.price\n",
      "name: price\n",
      "owner: user@website.com\n",
      "description: feature level description\n",
      "valueType: DOUBLE\n",
      "entity: usa_housing\n",
      "dataStores:\n",
      "  serving:\n",
      "    id: SERVING\n",
      "  warehouse:\n",
      "    id: WAREHOUSE\n",
      "\n",
      "Staging file to remote path gs://kubecon-19-gojek/staging/tmp_usa_housing_1557988085873.csv\n",
      "Submitting job with spec:\n",
      " type: file.csv\n",
      "sourceOptions:\n",
      "  path: gs://kubecon-19-gojek/staging/tmp_usa_housing_1557988085873.csv\n",
      "entities:\n",
      "- usa_housing\n",
      "schema:\n",
      "  entityIdColumn: area_code\n",
      "  fields:\n",
      "  - featureId: usa_housing.avg_area_income\n",
      "    name: avg_area_income\n",
      "  - featureId: usa_housing.avg_area_house_age\n",
      "    name: avg_area_house_age\n",
      "  - featureId: usa_housing.avg_area_number_of_rooms\n",
      "    name: avg_area_number_of_rooms\n",
      "  - featureId: usa_housing.avg_area_number_of_bedrooms\n",
      "    name: avg_area_number_of_bedrooms\n",
      "  - featureId: usa_housing.area_population\n",
      "    name: area_population\n",
      "  - featureId: usa_housing.price\n",
      "    name: price\n",
      "  - name: area_code\n",
      "  - name: timestamp\n",
      "  timestampColumn: timestamp\n",
      "\n",
      "Submitted job with id: feastimport1557988102681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'feastimport1557988102681'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from feast.sdk.resources.entity import Entity\n",
    "# from feast.sdk.resources.feature import Feature\n",
    "\n",
    "\n",
    "# # Register a simple entity\n",
    "# demo_entity = Entity(name='demo_entity', description='My simple demo entity')\n",
    "# fs.apply(demo_entity)\n",
    "\n",
    "# # Register five numeric features on this entity\n",
    "# from feast.sdk.resources.feature import Feature\n",
    "\n",
    "# my_simple\n",
    "\n",
    "# Now that we have finished creating our features, we ingest them into feast\n",
    "\n",
    "# Create importer\n",
    "importer = Importer.from_df(df, \n",
    "                           entity='usa_housing', \n",
    "                           owner='user@website.com',  \n",
    "                           staging_location=STAGING_LOCATION,\n",
    "                           id_column='area_code', \n",
    "                           timestamp_column='timestamp',\n",
    "                           serving_store=Datastore(id='SERVING'),\n",
    "                           warehouse_store=Datastore(id='WAREHOUSE'))\n",
    "\n",
    "# Update feature and entity metadata. Ideally you want to update these manually\n",
    "# so that they contain adequate information for the next user\n",
    "importer.entity.description = 'entity level description' \n",
    "for feature_id in importer.features:\n",
    "    importer.features[feature_id].description = 'feature level description'\n",
    "    \n",
    "# Ingest the feature data into the store\n",
    "fs.run(importer, apply_features=True, apply_entity=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Feature Set for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = FeatureSet(entity=\"usa_housing\", \n",
    "                         features=[\"usa_housing.avg_area_income\",\n",
    "                                   \"usa_housing.avg_area_house_age\",\n",
    "                                   \"usa_housing.avg_area_number_of_rooms\",\n",
    "                                   \"usa_housing.avg_area_number_of_bedrooms\",\n",
    "                                   \"usa_housing.area_population\",\n",
    "                                   \"usa_housing.price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve a Training Set from Feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating training dataset for features: ['usa_housing.avg_area_income', 'usa_housing.avg_area_house_age', 'usa_housing.avg_area_number_of_rooms', 'usa_housing.avg_area_number_of_bedrooms', 'usa_housing.area_population', 'usa_housing.price']\n",
      "created dataset usa_housing_1557990785896_20180101_20180131: aliz-development.fs_usa_housing.1557990785896_20180101_20180131\n"
     ]
    }
   ],
   "source": [
    "# Retrieve feature data for training from Feast\n",
    "dataset = fs.create_dataset(feature_set, \"2018-01-01\", \"2018-01-31\")\n",
    "training_df = fs.download_dataset_to_df(dataset, STAGING_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.158e+01 1.656e+05 1.207e+05 1.651e+03 1.520e+01] -2637299.0333282985\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Train model\n",
    "train_data = training_df[\n",
    "    ['avg_area_income', \n",
    "     'avg_area_house_age', \n",
    "     'avg_area_number_of_rooms', \n",
    "     'avg_area_number_of_bedrooms', \n",
    "     'area_population']].to_numpy()\n",
    "A = np.insert(train_data, len(train_data[0]), 1, axis=1)\n",
    "Y = training_df['price'].to_numpy()\n",
    "\n",
    "x = np.linalg.lstsq(A, Y, rcond=0)[0]\n",
    "m, b = x[:len(A[0])-1], x[len(A[0])-1]\n",
    "\n",
    "print(m, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845388.7662961711\n"
     ]
    }
   ],
   "source": [
    "serving_fs = FeatureSet(entity='usa_housing', \n",
    "                         features=['usa_housing.avg_area_income',\n",
    "                                   'usa_housing.avg_area_house_age',\n",
    "                                   'usa_housing.avg_area_number_of_rooms',\n",
    "                                   'usa_housing.avg_area_number_of_bedrooms',\n",
    "                                   'usa_housing.area_population'])\n",
    "\n",
    "def local_predict(id):\n",
    "    # retrieve features from Feast serving\n",
    "    features = fs.get_serving_data(serving_fs, entity_keys=[id])\n",
    "    x = features.to_numpy()[0][1:]\n",
    "    return sum(m * x) + b\n",
    "\n",
    "p = local_predict('FPO AE 09386')\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "MODEL_FILE = 'simple_model.dat'\n",
    "\n",
    "model = {\n",
    "    'm': m.tolist(),\n",
    "    'b': b,\n",
    "}\n",
    "\n",
    "model_path = os.path.join(os.getenv('HOME', '/home'), MODEL_FILE)\n",
    "print('writing to', model_path)\n",
    "\n",
    "with open(model_path, 'w+') as f:\n",
    "    json.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy with Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairing\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(PROJECT)\n",
    "BASE_IMAGE = 'gcr.io/kubeflow-images-public/fairing-base:v20190510'\n",
    "SERVING_LABEL = 'kubeflow-fairing-demo'\n",
    "\n",
    "print('docker registry:', DOCKER_REGISTRY)\n",
    "print('base image:', BASE_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deploy_with_fairing\n",
    "import uuid\n",
    "\n",
    "# To disambiguate between different deployments.\n",
    "serving_label = SERVING_LABEL + '-' + uuid.uuid4().hex[:4]\n",
    "print('Deploying service with selector', serving_label)\n",
    "\n",
    "# Register for docker credential. Needed for docker image pushes.\n",
    "_ = subprocess.call(['gcloud auth configure-docker --quiet'], shell=True)\n",
    "\n",
    "importlib.reload(deploy_with_fairing)\n",
    "deploy_with_fairing.deploy(DOCKER_REGISTRY, BASE_IMAGE, serving_label=serving_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from kubernetes import client, config\n",
    "\n",
    "# Need to set up KUBECONFIG. Kubernetes API client depends on it.\n",
    "subprocess.call(['gcloud', 'container', 'clusters', 'get-credentials', APP_NAME,\n",
    "                 '--zone', ZONE, '--project', PROJECT])\n",
    "config.load_kube_config()\n",
    "c = client.Configuration()\n",
    "client.Configuration.set_default(c)\n",
    "\n",
    "v1 = client.CoreV1Api()\n",
    "body = client.V1Service()\n",
    "label_selector = 'serving=%s' % serving_label\n",
    "resp = v1.list_service_for_all_namespaces(label_selector=label_selector)\n",
    "\n",
    "service_name = resp.items[0].metadata.name\n",
    "namespace = resp.items[0].metadata.namespace\n",
    "\n",
    "print('fairing service: {0}/{1}'.format(namespace, service_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving with Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def predict(url, data, feature_names=None):\n",
    "    pdata={\n",
    "        \"data\": {\n",
    "            \"names\":feature_names,\n",
    "            \"tensor\": {\n",
    "                \"shape\": np.asarray(data.shape).tolist(),\n",
    "                \"values\": data.flatten().tolist(),\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    serialized_data = json.dumps(pdata)\n",
    "    r = requests.post(url, data={'json':serialized_data})\n",
    "    return r\n",
    "\n",
    "def extract_prediction_array(content):\n",
    "    c = json.loads(content)\n",
    "    return np.array(c.get('data', {}).get('tensor', {}).get('values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "url = \"http://{service_name}.{namespace}.svc.cluster.local:5000/predict\".format(\n",
    "    service_name=service_name,\n",
    "    namespace=namespace)\n",
    "\n",
    "data = np.random.randint(1, high=100, size=100)\n",
    "r = predict(url, data)\n",
    "\n",
    "prediction = extract_prediction_array(r.content)\n",
    "print('prediction:')\n",
    "pprint.pprint(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
