{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacky Boilerplates\n",
    "- Install `feast` with pip.\n",
    "- Activate user service account with credentials JSON.\n",
    "- Hacks to retrieve essential information for deployments and serving.\n",
    "\n",
    "**NOTE**: This code block might hangs for a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install feast\n",
    "!pip install feast\n",
    "\n",
    "# Retrieve user service account.\n",
    "!gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "cred_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "cred = {}\n",
    "with open(cred_path, 'r') as c:\n",
    "    cred = json.load(c)\n",
    "\n",
    "PROJECT = cred['project_id']\n",
    "APP_NAME = re.search('([a-z\\-]+)-user'.format(PROJECT),\n",
    "                     cred['client_email']).group(1)\n",
    "p = subprocess.Popen(['gcloud', 'container', 'clusters', 'list',\n",
    "                      '--filter', 'name=%s' % APP_NAME, '--format', 'json'],\n",
    "                    stdout=subprocess.PIPE)\n",
    "out, _ = p.communicate()\n",
    "config = json.loads(out)[0]\n",
    "ZONE = config['zone']\n",
    "\n",
    "print('PROJECT =', PROJECT)\n",
    "print('APP_NAME =', APP_NAME)\n",
    "print('ZONE =', ZONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feast.sdk.resources.entity import Entity\n",
    "from feast.sdk.resources.storage import Storage\n",
    "from feast.sdk.resources.feature import Feature, Datastore, ValueType\n",
    "from feast.sdk.resources.feature_set import FeatureSet, FileType\n",
    "import feast.specs.FeatureSpec_pb2 as feature_pb\n",
    "\n",
    "from feast.sdk.importer import Importer\n",
    "\n",
    "from feast.sdk.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the local Feast deployment\n",
    "# FEAST_CORE_URL = '10.148.0.46:30576'\n",
    "# TODO(gabrielwen): Use internal DNS?\n",
    "FEAST_CORE_URL = '10.148.0.99:6565'\n",
    "FEAST_SERVING_URL = '10.148.0.100:6566'\n",
    "STAGING_LOCATION = 'gs://kubecon-19-gojek/staging'\n",
    "fs = Client(core_url=FEAST_CORE_URL,serving_url=FEAST_SERVING_URL, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load precomputed feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('usa_housing.csv', index_col=False)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register entity and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feast.sdk.resources.entity import Entity\n",
    "# from feast.sdk.resources.feature import Feature\n",
    "\n",
    "\n",
    "# # Register a simple entity\n",
    "# demo_entity = Entity(name='demo_entity', description='My simple demo entity')\n",
    "# fs.apply(demo_entity)\n",
    "\n",
    "# # Register five numeric features on this entity\n",
    "# from feast.sdk.resources.feature import Feature\n",
    "\n",
    "# my_simple\n",
    "\n",
    "# Now that we have finished creating our features, we ingest them into feast\n",
    "\n",
    "# TODO(gabrielwen): Skip ingestion if feature table is already there.\n",
    "\n",
    "# Create importer\n",
    "importer = Importer.from_df(df, \n",
    "                           entity='usa_housing', \n",
    "                           owner='user@website.com',  \n",
    "                           staging_location=STAGING_LOCATION,\n",
    "                           id_column='area_code', \n",
    "                           timestamp_column='timestamp',\n",
    "                           serving_store=Datastore(id='SERVING'),\n",
    "                           warehouse_store=Datastore(id='WAREHOUSE'))\n",
    "\n",
    "# Update feature and entity metadata. Ideally you want to update these manually\n",
    "# so that they contain adequate information for the next user\n",
    "importer.entity.description = 'entity level description' \n",
    "for feature_id in importer.features:\n",
    "    importer.features[feature_id].description = 'feature level description'\n",
    "    \n",
    "# Ingest the feature data into the store\n",
    "fs.run(importer, apply_features=True, apply_entity=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Feature Set for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_ID = 'usa_housing'\n",
    "FEATURES_SET = [\n",
    "    'usa_housing.avg_area_income',\n",
    "    'usa_housing.avg_area_house_age',\n",
    "    'usa_housing.avg_area_number_of_rooms',\n",
    "    'usa_housing.avg_area_number_of_bedrooms',\n",
    "    'usa_housing.area_population',\n",
    "]\n",
    "\n",
    "feature_set = FeatureSet(entity=ENTITY_ID, \n",
    "                         features=FEATURES_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve a Training Set from Feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature data for training from Feast\n",
    "dataset = fs.create_dataset(feature_set, \"2018-01-01\", \"2018-01-31\")\n",
    "training_df = fs.download_dataset_to_df(dataset, STAGING_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Train model\n",
    "train_data = training_df[[x.split('.')[1] for x in FEATURES_SET]].to_numpy()\n",
    "A = np.insert(train_data, len(train_data[0]), 1, axis=1)\n",
    "Y = training_df['price'].to_numpy()\n",
    "\n",
    "x = np.linalg.lstsq(A, Y, rcond=0)[0]\n",
    "m, b = x[:len(A[0])-1], x[len(A[0])-1]\n",
    "\n",
    "print(m, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_fs = FeatureSet(entity=ENTITY_ID, features=FEATURES_SET)\n",
    "\n",
    "def local_predict(id):\n",
    "    # retrieve features from Feast serving\n",
    "    features = fs.get_serving_data(serving_fs, entity_keys=[id])\n",
    "    x = features.to_numpy()[0][1:]\n",
    "    return sum(m * x) + b\n",
    "\n",
    "p = local_predict('FPO AE 09386')\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "MODEL_FILE = 'simple_model.dat'\n",
    "\n",
    "model = {\n",
    "    'm': m.tolist(),\n",
    "    'b': b,\n",
    "    'FEAST_CORE_URL': FEAST_CORE_URL,\n",
    "    'FEAST_SERVING_URL': FEAST_SERVING_URL,\n",
    "    'ENTITY_ID': ENTITY_ID,\n",
    "    'FEATURES_SET': FEATURES_SET,\n",
    "}\n",
    "\n",
    "# TODO(gabrielwen): Use PWD instead.\n",
    "model_path = os.path.join(os.getenv('HOME', '/home'), MODEL_FILE)\n",
    "print('writing to', model_path)\n",
    "\n",
    "with open(model_path, 'w+') as f:\n",
    "    json.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy with Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register for docker credential. Needed for docker image pushes.\n",
    "!gcloud auth configure-docker --quiet\n",
    "\n",
    "# Retrieve user service account.\n",
    "!gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairing\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(PROJECT)\n",
    "BASE_IMAGE = 'gcr.io/kubeflow-images-public/fairing-base:v20190516'\n",
    "SERVING_LABEL = 'kubeflow-fairing-demo'\n",
    "\n",
    "print('docker registry:', DOCKER_REGISTRY)\n",
    "print('base image:', BASE_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deploy_with_fairing\n",
    "import uuid\n",
    "\n",
    "# To disambiguate between different deployments.\n",
    "serving_label = SERVING_LABEL + '-' + uuid.uuid4().hex[:4]\n",
    "print('Deploying service with selector', serving_label)\n",
    "\n",
    "# TODO(gabrielwen): Re-deploy has permission issue.\n",
    "importlib.reload(deploy_with_fairing)\n",
    "deploy_with_fairing.deploy(DOCKER_REGISTRY, BASE_IMAGE, serving_label=serving_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch fairing service endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set up KUBECONFIG. Kubernetes API client depends on it.\n",
    "!gcloud container clusters get-credentials \"$APP_NAME\" --zone \"$ZONE\" --project \"$PROJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from kubernetes import client, config\n",
    "\n",
    "config.load_kube_config()\n",
    "c = client.Configuration()\n",
    "client.Configuration.set_default(c)\n",
    "\n",
    "v1 = client.CoreV1Api()\n",
    "body = client.V1Service()\n",
    "label_selector = 'serving=%s' % serving_label\n",
    "resp = v1.list_service_for_all_namespaces(label_selector=label_selector)\n",
    "\n",
    "service_name = resp.items[0].metadata.name\n",
    "namespace = resp.items[0].metadata.namespace\n",
    "\n",
    "print('fairing service: {0}/{1}'.format(namespace, service_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving with Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def predict(url, id):\n",
    "    pdata={\n",
    "        'strData': id,\n",
    "    }\n",
    "    serialized_data = json.dumps(pdata)\n",
    "    r = requests.post(url, data={'json':serialized_data})\n",
    "    return r\n",
    "\n",
    "def extract_prediction_array(content):\n",
    "    c = json.loads(content)\n",
    "    return np.array(c.get('data', {}).get('ndarray', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "url = \"http://{service_name}.{namespace}.svc.cluster.local:5000/predict\".format(\n",
    "    service_name=service_name,\n",
    "    namespace=namespace)\n",
    "\n",
    "r = predict(url, 'FPO AE 09386')\n",
    "prediction = extract_prediction_array(r.content)\n",
    "print('prediction:')\n",
    "pprint.pprint(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
